# -*- coding: utf-8 -*-
"""VGG_16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dOZ5aSn4D2t50o-v0cBgx3fLrk-opW5m

#**Pretrained Network**

Küçük görüntü veri setleri hakkında derin öğrenmeye yönelik yaygın ve etkili bir yaklaşım, önceden eğitilmiş (*pretrained*) bir ağdan yararlanmaktır.  

**VGG16**:
<p align="center">
<img src="https://i.hizliresim.com/Nd8Aav.png" width="750">
</p>

<p align="center">
<img src="https://i.hizliresim.com/uTrPZJ.png" width="750">
</p>

## **VGG16'yı Test Edelim;**
"""

from keras.applications import VGG16
import matplotlib.pyplot as plt
from keras.preprocessing import image
import numpy as np
import json
import os

model = VGG16(weights="imagenet", #ImageNet dataset icin egitilmis agirliklar
              include_top = True, #Dense Layer'i kullan.
              input_shape=(224, 224, 3))

model.summary()

"""`138,357,544` tane eğitilebilir parametre var. Bu parametreleri kaydetmek istersek, `138357544*4/1024/1024 = 527.79MB` boyutunda yer kaplar.  

Şimdi bu modeli bir test görüntüsü ile deneyelim;
"""

img_path="/content/drive/MyDrive/Works/Deep_Learning/VGG_16/test_img/warplane_test.png"

input1 = image.load_img(img_path, target_size=(224, 224))
plt.imshow(input1)
#Image'i numpy array'e donustur;
input = image.img_to_array(input1)

#Image'i networke uygula;
y = model.predict(input.reshape(1, 224, 224, 3))
# 1 olmasinin sebebi 1 adet image olmasi.

"""y'ye baktığımızda 1000 classın olasılıklarını göreceğiz.

1000 tane class olduğunu kontrol edelim;
"""

print(y.shape)

"""`softmax` kullandığımızdan dolayı output olarak olasılıklar görüyoruz. y'nin içerisindeki olasılıkların toplamı 1.0 olmalıdır;"""

print("sum:", np.sum(y))

"""`np.argmax()` ile en yüksek olasılığın hangi classa ait olduğuna bakalım;"""

print("highest probability:", np.argmax(y))

"""`imagenet_class_index.json` dosyasından hangi class'ın neye ait olduğuna bakalım;"""

pred_index = np.argmax(y)
pred_perc = y[0][pred_index]*100
print("Predict percentage:", pred_perc)

json_path="/content/drive/MyDrive/Works/Deep_Learning/VGG_16/vgg16_class/imagenet_class_index.json"
with open(json_path) as json_file:
  labels = json.load(json_file)

#belirlenen etiket
id1, class1 = labels[str(pred_index)]
print("Class:", class1)

"""Bu tarz networklerde sonuç olarak tek bir class'a bakılmaz, top 5, top 10 gibi sonuçlara bakılır;

`np.argsort()` bize tahmin edilen classların indexlerini küçükten büyüğe sıralayarak verir.
"""

predicts = np.argsort(y[0])

top_5 = predicts[999:994:-1] #top-5 accuracy
print("Top 5 class;")

for count,ind in enumerate(top_5):
  id1, class1 = labels[str(ind)]
  print("Class",count+1,"=", class1,"\t%",
        (100*y[0][ind]).astype("float32"))
  
plt.imshow(input1);

"""**%84.1** olasılık ile savaş uçağı olduğunu tespit etti.

###**Görselleştirme;**
"""

list_name=os.listdir('/content/drive/MyDrive/Works/Deep_Learning/VGG_16/test_img/')
test_dir='/content/drive/MyDrive/Works/Deep_Learning/VGG_16/test_img/'

for x,name in enumerate(list_name):
    path=test_dir+name
    input1=image.load_img(path,
                          target_size=(224,224))
    #Numpy dizisine dönüştür
    input=image.img_to_array(input1)
    #Görüntüyü ağa uygula
    y=model.predict(input.reshape(1,224,224,3))

    json_file = open('/content/drive/MyDrive/Works/Deep_Learning/VGG_16/vgg16_class/imagenet_class_index.json')
    labels=json.load(json_file)
    json_file.close()
    with open("/content/drive/MyDrive/Works/Deep_Learning/VGG_16/vgg16_class/imagenet_class_index.json") as dosya:
        etiketler=json.load(dosya)

    #top5 accuracy
    #kucukten buyuge dogru tahminleri sıraladı
    predicts=np.argsort(y[0])
    top_5=predicts[999:994:-1]#top5 accuracy
    #tahminleri yazdir
    fig = plt.figure()
    plt.subplot(1,4,x+1)
    plt.xticks([])
    plt.yticks([])
    top5_list=[]
    for count,ind in enumerate(top_5):
        id1,class1=labels[str(ind)]
        top5_list.append(['Class',count+1,'=',class1,"%",(100*y[0][ind]).astype('int')])
    plt.xlabel("{0}\n{1}\n{2}\n{3}\n{4}".format(* top5_list).replace(",", "").replace("'", ""))
    fig.tight_layout()
    #örnek görüntüyü göster
    plt.imshow(input1)

"""# **VGG16 ile Cat-Dog Verisetinin Eğitimi**

## **Feature Extraction**

Bu kez VGG16'nın Dense Layer'larını kullanmayıp kendimiz Dense Layer ekleyeceğiz.
Örnekte, modelin eğitimi iki şekilde gerçekleştirilecektir:


*   Birinci yaklaşımda, görüntülerin her biri VGG16 ağına uygulanacak
ve konvolüsyon katmanı çıkısında elde edilen vektörler
kaydedilecektir. Ardından bu veriler ikili sınıflandırma için yeniden
tanımlanmış yoğun katman (dense layer) için giriş olarak kullanılarak
yoğun katmanın eğitimi gerçekleştirilecektir.

*   İkinci yaklaşımda, VGG16 ağının yoğun katmanı çıkartılıp, ikili
sınıflandırma için tanımlanan yeni yoğun katman eklenecek.
Böylece model eğitimde bir bütün olarak kullanılacaktır. Ancak
konvolüsyon katmanının ağırlıkları dondurularak eğitim sırasında
değişmesi engellenecektir. Ayrıca, iyileştirme için çıkış katmanından
geriye doğru birkaç katman daha eğitime dahil edilerek başarıma
etkisi gösterilecektir.

### **1. Yöntem**

Birinci yaklaşımda, görüntülerin her biri VGG16 ağına uygulanacak ve konvolüsyon katmanı çıkısında elde edilen vektörler kaydedilecektir. Ardından bu veriler ikili sınıflandırma için yeniden tanımlanmış yoğun katman (dense layer) için giriş olarak kullanılarak yoğun katmanın eğitimi gerçekleştirilecektir.
"""

!cp -r /content/drive/MyDrive/Works/Deep_Learning/CNN_Cat-Dog/data.zip .
!unzip -q data.zip
!rm data.zip

from keras.preprocessing.image import ImageDataGenerator
import os

base_dir = "data-catdog/"

train_dir = os.path.join(base_dir, "train")
validation_dir = os.path.join(base_dir, "validation")
test_dir = os.path.join(base_dir, "test")

datagen = ImageDataGenerator(rescale=1./255)
batch_size = 20

"""Önceden eğitilmiş ağı yükle;"""

conv_base = VGG16(weights="imagenet",
              include_top=False, #Dense Layer yok.
              input_shape = (150, 150, 3))

conv_base.summary()

"""Seçilen görüntüleri ağa uygulayıp ağ çıkışını `features` dizisine kaydet.  Görüntülerle ilgili etiketleri de `labels` dizisine kaydet"""

def extract_features(directory, sample_count):
  features = np.zeros(shape=(sample_count, 4, 4, 512))
  labels = np.zeros(shape=(sample_count))
  generator = datagen.flow_from_directory(
      directory,
      target_size=(150,150),
      batch_size=batch_size,
      class_mode="binary")
  i=0
  for inputs_batch, labels_batch in generator:
    features_batch = conv_base.predict(inputs_batch)
    features[i*batch_size : (i+1) * batch_size] = features_batch
    labels[i*batch_size : (i+1) * batch_size] = labels_batch
    i += 1
    if i*batch_size >= sample_count:
      break
  return features, labels

"""Train, validation ve test görüntüleri, tanımladığımız `extract_features()` ile önceden eğitimli ağa uygulanır."""

train_features, train_labels = extract_features(train_dir, 2000)
validation_features, validation_labels = extract_features(validation_dir, 1000)
test_features, test_labels = extract_features(test_dir, 1000)

train_features = np.reshape(train_features, (2000, 4*4*512))
validation_features = np.reshape(validation_features, (1000, 4*4*512))
test_features = np.reshape(test_features, (1000, 4*4*512))

from keras import models
from keras import layers
from keras import optimizers

"""Eğiteceğimiz ağ sadece Dense katmanlardan oluşuyor. Conv2D katmanlarını hazır kullandığımız için eğiteceğimiz modelin içerisinde tekrar tanımlanmaz."""

model = models.Sequential()
model.add(layers.Dense(256, activation="relu", input_dim=4*4*512))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation="sigmoid"))

model.compile(optimizer = optimizers.RMSprop(lr=2e-5),
              loss="binary_crossentropy",
              metrics=["acc"])

"""Önceden eğitimli konvolüsyon ağının çıkışındaki veriler Dense Layer katmanına uygulanarak ağı eğitmek için kullanılır."""

history = model.fit(train_features, train_labels,
                    epochs=30,
                    batch_size=20,
                    validation_data=(validation_features, validation_labels))

def plot_acc_loss(x):  
  acc = x.history["acc"]
  val_acc = x.history["val_acc"]
  loss = x.history["loss"]
  val_loss = x.history["val_loss"]
  print("acc =", acc[-1])
  print("val_acc = ", val_acc[-1])
  print("loss =", loss[-1])
  print("val_loss =", val_loss[-1])
  epochs = range(1, len(acc) + 1)
  fig = plt.figure()
  plt.subplot(2,1,1)
  plt.plot(epochs, acc, "bo", label="Training acc")
  plt.plot(epochs, val_acc, "b", label="Validation acc")
  plt.xlabel("Epochs")
  plt.ylabel("Accuracy")
  plt.title("Training and Validation Accuracy")

  plt.subplot(2,1,2)
  plt.plot(epochs, loss, "bo", label="Training loss")
  plt.plot(epochs, val_loss, "b", label="Validation loss")
  plt.title("Training and Validation Loss")
  plt.xlabel("Epochs")
  plt.ylabel("Loss")
  plt.legend()
  #fig.tight_layout()
  plt.show()
  
  

plot_acc_loss(history)

"""### **2. Yöntem**

**VGG16 Ağırlıklarının Eğitim Dışında Tutulması**  
*Training the model end to end with a frozen convolutional base*

İkinci yaklaşımda, VGG16 ağının yoğun katmanı çıkartılıp, ikili sınıflandırma için tanımlanan yeni yoğun katman eklenecek. Böylece model eğitimde bir bütün olarak kullanılacaktır. Ancak konvolüsyon katmanının ağırlıkları dondurularak eğitim sırasında değişmesi engellenecektir. Ayrıca, iyileştirme için çıkış katmanından geriye doğru birkaç katman daha eğitime dahil edilerek başarıma etkisi gösterilecektir.

Modeli tanımlarken konvolüsyon katmanı olarak VGG16 ağını kullanıyoruz.
"""

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.summary()

"""`Non-trainable params: 0` olduğundan, modeli bu şekilde eğitirsek konvolüsyonları da eğitir.

Önceden eğitilmiş ağın parametrelerini kullanmak için donduruyoruz. Dondurmazsak VGG16 mimarisine ait parametreleri de eğitebiliriz. Ancak VGG16 daha önce 1.4 milyon görüntü ile eğitilmiş olduğu için, daha az veri ile eğittiğimiz ağın başarımını artırabilir. Daha önceki örnekte de bu ağı kullanmıştık ve eğitimden önce görüntüleri önce VGG16’dan geçirmiştik. Bu örnekte VGG16’yı da model yapısına eklediğimiz için buna gerek yok. Bu örnekte ayrıca veri zenginleştirme de yapılarak başarım artışı elde edilecektir.
"""

conv_base.trainable=False #conv_base katmaninin agirliklarini dondurur.
model.summary()

"""Burada dikkat etmemiz gereken nokta;

```
Non-trainable params: 14,714,688
```


"""

train_datagen = ImageDataGenerator(
                          rescale=1./255,
                          rotation_range=40,
                          width_shift_range=0.2,
                          height_shift_range=0.2,
                          shear_range=0.2,
                          zoom_range=0.2,
                          horizontal_flip=True,
                          fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    target_size=(150, 150), #Resizes all images to 150 × 150
                                                    batch_size=20,
                                                    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(validation_dir,
                                                        target_size=(150, 150),
                                                        batch_size=20,
                                                        class_mode='binary')

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['acc'])

history = model.fit_generator(train_generator,
                              steps_per_epoch=100,
                              epochs=30,
                              validation_data=validation_generator,
                              validation_steps=50)

plot_acc_loss(history)

"""### **Fine Tuning**

Önceden eğitilmiş ağ üzerinde ince ayar.

<p align="center">
<img src="https://i.hizliresim.com/6Iwg4E.png">
</p>
"""

conv_base.summary()

"""Ağ içerisindeki katman isimlerini `conv_base.layers` ile al.  
Eğer isim beşinci bloğa aitse `set_trainable=True` yapılarak blok eğitime dahil edilir.
"""

conv_base.trainable = True
set_trainable = False

for layer in conv_base.layers:
  if layer.name == 'block5_conv1':
    set_trainable = True
  if set_trainable:
    layer.trainable = True #5. katmandan sonrakileri trainable yap.
  else:
    layer.trainable = False

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-5),
              metrics=['acc'])

history = model.fit_generator(train_generator,
                              steps_per_epoch=100,
                              epochs=100,
                              validation_data=validation_generator,
                              validation_steps=50)

plot_acc_loss(history)

"""Test verilerinde model başarımını ölçelim;"""

test_generator = test_datagen.flow_from_directory(test_dir,
                                                  target_size=(150, 150),
                                                  batch_size=20,
                                                  class_mode='binary')

test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)
print('test acc:', test_acc)